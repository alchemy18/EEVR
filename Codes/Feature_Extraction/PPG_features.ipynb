{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import neurokit2 as nk\n",
    "import cvxEDA.src.cvxEDA as cvxEDA\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapz\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sampling_freq = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ppg = pd.read_csv(\"../Data_files/PPG.csv\")\n",
    "raw_ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = raw_ppg[raw_ppg['CMA'].isin(['HVLA', 'LVLA', 'LVHA', 'HVHA', 'Baseline'])]\n",
    "final_df['CMA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Video_ID_number'] = [int(part.split('V')[-1]) for part in final_df['Video ID']]\n",
    "final_df['Video_ID_number']\n",
    "final_df.to_csv(\"Stimuli_PPG.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Participant ID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prep(merged_df):\n",
    "    vads = pd.read_csv(\"VADS.csv\") #getting label csv\n",
    "    print(\"reading vad\")\n",
    "\n",
    "    #adding arousal, valence and dominance columns to orginal data csv\n",
    "    for index, row in tqdm(merged_df.iterrows()):\n",
    "        matching_rows = vads[(vads['Participant ID'] == row['Participant ID']) & (vads['Video ID'] == row['Video_ID_number'])]\n",
    "\n",
    "        if not matching_rows.empty:\n",
    "\n",
    "            merged_df.at[index, 'Valence'] = matching_rows['Valence'].iloc[0]\n",
    "            merged_df.at[index, 'Arousal'] = matching_rows['Arousal'].iloc[0]\n",
    "            merged_df.at[index, 'Dominance'] = matching_rows['Dominance'].iloc[0]\n",
    "            merged_df.at[index, 'significance'] = matching_rows['significance'].iloc[0]\n",
    "\n",
    "    print(\"binning...\")\n",
    "    # Define the bins and labels for categorization\n",
    "    bins = [1, 3, 5]  # Define the bin edges\n",
    "    labels = [0, 1]   # Define the corresponding labels (0 (Low) for 1-3:, 1 (High) for 4-5)\n",
    "\n",
    "    # Use the cut function to categorize the 'arousal' column\n",
    "    merged_df['arousal_category'] = pd.cut(merged_df['Arousal'], bins=bins, labels=labels, include_lowest=True)\n",
    "    merged_df['valence_category'] = pd.cut(merged_df['Valence'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "    # Convert the 'category' column to integer type if needed\n",
    "    merged_df['arousal_category'] = merged_df['arousal_category'].astype(int)\n",
    "    merged_df['valence_category'] = merged_df['valence_category'].astype(int)\n",
    "\n",
    "    print(\"mapping\")\n",
    "    mapping = {\n",
    "    'Baseline': 0,\n",
    "    'LVLA': 0,\n",
    "    'LVHA': 0,\n",
    "    'HVHA': 1,\n",
    "    'HVLA': 1  # Baseline and HVLA mapped to 0\n",
    "    }\n",
    "\n",
    "    # Apply the mapping to the 'CMA' column\n",
    "    merged_df['taskwiselabel'] = merged_df['CMA'].map(mapping)\n",
    "    # autofet_df\n",
    "\n",
    "    three_class_mapping = {\n",
    "    'Baseline': 1,\n",
    "    'LVLA': 1,\n",
    "    'LVHA': 0,\n",
    "    'HVHA': 1,\n",
    "    'HVLA': 2  \n",
    "    }\n",
    "\n",
    "    merged_df['three_class_label'] = merged_df['CMA'].map(three_class_mapping)\n",
    "    return merged_df\n",
    "\n",
    "# ppg_data_with_labels = label_prep(final_df)\n",
    "# ppg_data_with_labels.to_csv(\"PPG_data_with_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = {}\n",
    "for pi in final_df['Participant ID'].unique():\n",
    "    df_pi = final_df[final_df['Participant ID'] == pi]\n",
    "    for vi in final_df['Video ID'].unique():\n",
    "        # print(pi,vi)\n",
    "        df_vi =  df_pi[df_pi['Video ID'] == vi]\n",
    "        tag = str(pi) + '_' + vi\n",
    "        df_list[tag] = (df_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 125\n",
    "out_df = pd.DataFrame()\n",
    "all_participants_stats = []\n",
    "\n",
    "for i in df_list:\n",
    "\n",
    "    row_dict = {}\n",
    "\n",
    "    pid = df_list[i]['Participant ID'].tolist()[0]\n",
    "    vid = df_list[i]['Video ID'].tolist()[0]\n",
    "    gender = df_list[i]['Gender'].tolist()[0]\n",
    "    cma = df_list[i]['CMA'].tolist()[0]\n",
    "    vnum = df_list[i]['Video_ID_number'].tolist()[0]\n",
    "    bpm = df_list[i]['BPM'].tolist()[0]\n",
    "    ibi = df_list[i]['IBI'].tolist()[0]\n",
    "\n",
    "    ppgdata = df_list[i]['PPG'].to_numpy()\n",
    "    # print(ppgdata.shape)\n",
    "\n",
    "    # Combine participant info with computed statistics\n",
    "    row_dict.update({\n",
    "        'Participant ID': pid,\n",
    "        'Video ID': vid,\n",
    "        'Gender': gender,\n",
    "        'CMA': cma,\n",
    "        'Video_ID_number': vnum,\n",
    "        'BPM': bpm,\n",
    "        'IBI': ibi\n",
    "    })\n",
    "\n",
    "    #cleaning ppg data\n",
    "    ppg_clean = nk.ppg_clean(ppgdata)\n",
    "    ppg_signals, info = nk.ppg_process(ppg_clean, sampling_rate=sampling_freq)\n",
    "    # print(ppg_signals['PPG_Peaks'].unique())\n",
    "    analyze_df = nk.ppg_analyze(ppg_signals, sampling_rate=sampling_freq) \n",
    "    row_dict.update(analyze_df.iloc[0])\n",
    "\n",
    "    # Add the row to the results list\n",
    "    all_participants_stats.append(row_dict)\n",
    "\n",
    "df_all_stats = pd.DataFrame(all_participants_stats)\n",
    "df_all_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with NaN values\n",
    "df_all_stats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "columns_with_nan = df_all_stats.columns[df_all_stats.isna().any()].tolist()\n",
    "columns_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['HRV_SDANN1',\n",
    " 'HRV_SDNNI1',\n",
    " 'HRV_SDANN2',\n",
    " 'HRV_SDNNI2',\n",
    " 'HRV_SDANN5',\n",
    " 'HRV_SDNNI5',\n",
    " 'HRV_ULF',\n",
    " 'HRV_VLF',\n",
    " 'HRV_DFA_alpha2',\n",
    " 'HRV_MFDFA_alpha2_Width',\n",
    " 'HRV_MFDFA_alpha2_Peak',\n",
    " 'HRV_MFDFA_alpha2_Mean',\n",
    " 'HRV_MFDFA_alpha2_Max',\n",
    " 'HRV_MFDFA_alpha2_Delta',\n",
    " 'HRV_MFDFA_alpha2_Asymmetry',\n",
    " 'HRV_MFDFA_alpha2_Fluctuation',\n",
    " 'HRV_MFDFA_alpha2_Increment', 'HRV_SampEn']\n",
    "\n",
    "df_all_stats = df_all_stats.drop(columns=columns_to_drop)\n",
    "# df_all_stats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# df_all_stats.dropna(axis=1)\n",
    "columns_with_nan = df_all_stats.columns[df_all_stats.isna().any()].tolist()\n",
    "columns_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fet_ppg = df_all_stats[['BPM',\n",
    "#        'IBI', 'max_ppg', 'min_ppg', 'mean_ppg', 'sd_ppg', 'ku_ppg', 'sk_ppg',\n",
    "#        'median_ppg', 'q1_ppg', 'q3_ppg', 'q05_ppg', 'q95_ppg', 'meanHR',\n",
    "#        'minHR', 'maxHR', 'sdHR', 'modeHR', 'nNN', 'meanNN', 'SDSD', 'CVNN',\n",
    "#        'SDNN', 'pNN50', 'pNN20', 'RMSSD', 'medianNN', 'q20NN', 'q80NN',\n",
    "#        'minNN', 'maxNN', 'triHRV', 'totalpower', 'LF', 'HF', 'ULF', 'VLF',\n",
    "#        'VHF', 'LF/HF', 'rLF', 'rHF', 'peakLF', 'peakHF', 'SD1', 'SD2',\n",
    "#        'SD1SD2', 'apEn', 'sampEn']]\n",
    "\n",
    "fet_ppg = df_all_stats[['BPM',\n",
    "       'IBI', 'PPG_Rate_Mean', 'HRV_MeanNN', 'HRV_SDNN', 'HRV_RMSSD',\n",
    "       'HRV_SDSD', 'HRV_CVNN', 'HRV_CVSD', 'HRV_MedianNN', 'HRV_MadNN',\n",
    "       'HRV_MCVNN', 'HRV_IQRNN', 'HRV_SDRMSSD', 'HRV_Prc20NN', 'HRV_Prc80NN',\n",
    "       'HRV_pNN50', 'HRV_pNN20', 'HRV_MinNN', 'HRV_MaxNN', 'HRV_HTI',\n",
    "       'HRV_TINN', 'HRV_LF', 'HRV_HF', 'HRV_VHF', 'HRV_TP', 'HRV_LFHF',\n",
    "       'HRV_LFn', 'HRV_HFn', 'HRV_LnHF', 'HRV_SD1', 'HRV_SD2', 'HRV_SD1SD2',\n",
    "       'HRV_S', 'HRV_CSI', 'HRV_CVI', 'HRV_CSI_Modified', 'HRV_PIP',\n",
    "       'HRV_IALS', 'HRV_PSS', 'HRV_PAS', 'HRV_GI', 'HRV_SI', 'HRV_AI',\n",
    "       'HRV_PI', 'HRV_C1d', 'HRV_C1a', 'HRV_SD1d', 'HRV_SD1a', 'HRV_C2d',\n",
    "       'HRV_C2a', 'HRV_SD2d', 'HRV_SD2a', 'HRV_Cd', 'HRV_Ca', 'HRV_SDNNd',\n",
    "       'HRV_SDNNa', 'HRV_DFA_alpha1', 'HRV_MFDFA_alpha1_Width',\n",
    "       'HRV_MFDFA_alpha1_Peak', 'HRV_MFDFA_alpha1_Mean',\n",
    "       'HRV_MFDFA_alpha1_Max', 'HRV_MFDFA_alpha1_Delta',\n",
    "       'HRV_MFDFA_alpha1_Asymmetry', 'HRV_MFDFA_alpha1_Fluctuation',\n",
    "       'HRV_MFDFA_alpha1_Increment', 'HRV_ApEn', 'HRV_ShanEn',\n",
    "       'HRV_FuzzyEn', 'HRV_MSEn', 'HRV_CMSEn', 'HRV_RCMSEn', 'HRV_CD',\n",
    "       'HRV_HFD', 'HRV_KFD', 'HRV_LZC']]\n",
    "\n",
    "ppg_label = df_all_stats[['Participant ID', 'Video ID', 'Gender', 'CMA', 'Video_ID_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_eda = MinMaxScaler()\n",
    "fet_ppg_scaled = pd.DataFrame(columns=fet_ppg.columns, index=fet_ppg.index)\n",
    "fet_ppg_scaled[fet_ppg_scaled.columns] = scaler_eda.fit_transform(fet_ppg)\n",
    "fet_ppg_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = fet_ppg_scaled.corr()\n",
    "\n",
    "# Identify redundant features\n",
    "redundant_features = []\n",
    "for feature in correlation_matrix.columns:\n",
    "    correlated_features = correlation_matrix.index[\n",
    "        (correlation_matrix[feature] > 0.90) & (correlation_matrix.index != feature)\n",
    "    ]\n",
    "    redundant_features.extend(correlated_features)\n",
    "\n",
    "redundant_features = list(set(redundant_features))\n",
    "print(redundant_features)\n",
    "selected_features = [feature for feature in correlation_matrix.columns if feature not in redundant_features]\n",
    "\n",
    "# Create a subset of the correlation matrix for selected features\n",
    "reduced_correlation_matrix = correlation_matrix.loc[selected_features, selected_features]\n",
    "\n",
    "# Create a correlation heatmap using Seaborn\n",
    "plt.figure(figsize=(10, 10))  # Adjust the figure size as needed\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(reduced_correlation_matrix, annot=True, cmap='viridis', cbar=True, square=True,\n",
    "            fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap for PPG Features')\n",
    "plt.show()\n",
    "\n",
    "print(reduced_correlation_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppg_final_fet = fet_ppg_scaled[['BPM', 'IBI', 'max_ppg', 'min_ppg', 'mean_ppg', 'sk_ppg', 'median_ppg',\n",
    "#        'meanHR', 'minHR', 'maxHR', 'sdHR', 'modeHR', 'nNN', 'SDNN', 'pNN50',\n",
    "#        'pNN20', 'medianNN', 'q20NN', 'q80NN', 'minNN', 'maxNN', 'triHRV', 'LF',\n",
    "#        'HF', 'ULF', 'VHF', 'LF/HF', 'rLF', 'rHF', 'peakLF', 'peakHF', 'SD1SD2',\n",
    "#        'apEn']]\n",
    "\n",
    "ppg_final_fet = fet_ppg_scaled[['BPM', 'IBI', 'PPG_Rate_Mean', 'HRV_MedianNN', 'HRV_Prc20NN',\n",
    "       'HRV_MinNN', 'HRV_HTI', 'HRV_TINN', 'HRV_LF', 'HRV_VHF', 'HRV_LFn',\n",
    "       'HRV_HFn', 'HRV_LnHF', 'HRV_SD1SD2', 'HRV_CVI', 'HRV_PSS', 'HRV_PAS',\n",
    "       'HRV_PI', 'HRV_C1d', 'HRV_C1a', 'HRV_DFA_alpha1',\n",
    "       'HRV_MFDFA_alpha1_Width', 'HRV_MFDFA_alpha1_Peak',\n",
    "       'HRV_MFDFA_alpha1_Mean', 'HRV_MFDFA_alpha1_Max',\n",
    "       'HRV_MFDFA_alpha1_Delta', 'HRV_MFDFA_alpha1_Asymmetry', 'HRV_ApEn',\n",
    "       'HRV_ShanEn', 'HRV_FuzzyEn', 'HRV_MSEn', 'HRV_CMSEn', 'HRV_RCMSEn',\n",
    "       'HRV_CD', 'HRV_HFD', 'HRV_KFD', 'HRV_LZC']]\n",
    "ppg_final_fet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([ppg_final_fet, ppg_label], axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vads = pd.read_csv(\"../Data_files/VADS.csv\")\n",
    "vads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(merged_df.iterrows()):\n",
    "    matching_rows = vads[(vads['Participant ID'] == row['Participant ID']) & (vads['Video ID'] == row['Video_ID_number'])]\n",
    "\n",
    "    if not matching_rows.empty:\n",
    "\n",
    "        merged_df.at[index, 'Valence'] = matching_rows['Valence'].iloc[0]\n",
    "        merged_df.at[index, 'Arousal'] = matching_rows['Arousal'].iloc[0]\n",
    "        merged_df.at[index, 'Dominance'] = matching_rows['Dominance'].iloc[0]\n",
    "        merged_df.at[index, 'significance'] = matching_rows['significance'].iloc[0]\n",
    "        \n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins and labels for categorization\n",
    "bins = [1, 3, 5]  # Define the bin edges\n",
    "labels = [0, 1]   # Define the corresponding labels (0 (Low) for 1-3:, 1 (High) for 4-5)\n",
    "\n",
    "# Use the cut function to categorize the 'arousal' column\n",
    "merged_df['arousal_category'] = pd.cut(merged_df['Arousal'], bins=bins, labels=labels, include_lowest=True)\n",
    "merged_df['valence_category'] = pd.cut(merged_df['Valence'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Convert the 'category' column to integer type if needed\n",
    "merged_df['arousal_category'] = merged_df['arousal_category'].astype(int)\n",
    "merged_df['valence_category'] = merged_df['valence_category'].astype(int)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Baseline': 0,\n",
    "    'LVLA': 0,\n",
    "    'LVHA': 1,\n",
    "    'HVHA': 1,\n",
    "    'HVLA': 0  # Baseline and HVLA mapped to 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'CMA' column\n",
    "merged_df['CMA_numeric'] = merged_df['CMA'].map(mapping)\n",
    "# autofet_df\n",
    "\n",
    "merged_df['task_valence'] = merged_df['CMA'].apply(lambda x: 0 if x in ['Baseline', 'HVLA'] else 1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(final_fet, valence_col, arousal_col, stress_col, valence, arousal, task_valence):\n",
    "\n",
    "    # Apply t-SNE to reduce dimensions\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(final_fet)\n",
    "\n",
    "    # Create a DataFrame with t-SNE results\n",
    "    tsne_df = pd.DataFrame(tsne_results, columns=['t-SNE1', 't-SNE2'])\n",
    "    tsne_df['Label'] = valence_col\n",
    "\n",
    "    # Plotting the t-SNE results with colors based on labels\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(tsne_df['t-SNE1'], tsne_df['t-SNE2'], c=tsne_df['Label'], cmap='viridis')\n",
    "    plt.title(f't-SNE Plot of Features Colored by {valence}')\n",
    "    plt.xlabel('t-SNE1')\n",
    "    plt.ylabel('t-SNE2')\n",
    "    plt.colorbar(scatter, label='Label')\n",
    "    plt.show()\n",
    "\n",
    "    tsne_df['Label'] = arousal_col\n",
    "\n",
    "    # Plotting the t-SNE results with colors based on labels\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(tsne_df['t-SNE1'], tsne_df['t-SNE2'], c=tsne_df['Label'], cmap='viridis')\n",
    "    plt.title(f't-SNE Plot of Features Colored by {arousal}')\n",
    "    plt.xlabel('t-SNE1')\n",
    "    plt.ylabel('t-SNE2')\n",
    "    plt.colorbar(scatter, label='Label')\n",
    "    plt.show()\n",
    "\n",
    "    tsne_df['Label'] = stress_col\n",
    "\n",
    "    # Plotting the t-SNE results with colors based on labels\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(tsne_df['t-SNE1'], tsne_df['t-SNE2'], c=tsne_df['Label'], cmap='viridis')\n",
    "    plt.title(f't-SNE Plot of Features Colored by {task_valence}')\n",
    "    plt.xlabel('t-SNE1')\n",
    "    plt.ylabel('t-SNE2')\n",
    "    plt.colorbar(scatter, label='Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPG_data_with_labels = label_prep(merged_df)\n",
    "PPG_data_with_labels.to_csv(\"../Data_files/PPG_labels.csv\")\n",
    "PPG_data_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(ppg_final_fet, merged_df['valence_category'], merged_df['arousal_category'], merged_df['task_valence'], 'valence', 'arousal', 'CMA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
